\centerline{\Large{\textbf{Abstract}}}

\vspace{0.6cm}

\noindent My thesis is about the utilisation of health data assets, in which I focused on two different topics: one being control group selection while the other is extracting information from medical documents. 

Observational studies are often based on case-control studies in which the conclusion (for example, the effect of a drug on healing) is drawn based on the comparison of case (treated) and control (untreated) groups. The basic criterion for the proper execution of case-control studies is the selection of appropriate case and control groups. In retrospective studies, the treated group is usually predetermined, and a control group must be selected for the study, in which the individuals are very similar to the subjects of the case group in terms of their basic characteristics that influence the investigated question. In my thesis, I proposed two new nearest-neighbour-based control group selection methods, which perform the selection of individuals in the original n-dimensional feature space. I tested the effectiveness of the proposed methods with Monte Carlo simulations using self-proposed dissimilarity measures and other widely used similarity measures. 

In everyday medical practice, the results of echocardiograms are usually recorded in the form of unstructured text, from which extracting relevant information is a challenging task. To support this information extraction, I developed a text mining-based information extraction method that automatically identifies and standardises the descriptions of the heart ultrasound measurement in the findings, and then stores the extracted and standardised measurement descriptions together with the measurement results in a structured form. Through case studies based on large data sets, I have shown that the proposed method can be used to extract measurement results from echocardiography documents with high reliability without performing a direct search or having detailed information about the structure of the document and data recording habits. The proposed methodology effectively handles spelling errors, abbreviations, and varied terminology used in descriptions.
